{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DMTM_Prj.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "0d706811-b70c-aeab-a78b-3c7abd9978d3",
        "id": "mG5CP9Lx6nJq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Statistical libraries\n",
        "from scipy import stats\n",
        "from scipy.stats import skew\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Plotting libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Evaluation Procedures\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Classification methods\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Evaluation Metrics\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMBNmHrKVVJv"
      },
      "source": [
        "## Variable\n",
        "Set values of some variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2llkUq1oVdns"
      },
      "source": [
        "SEED = 1234"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uIIo-WZTd8e"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTU23DQbOfGa"
      },
      "source": [
        "all_data = pd.read_csv(\"train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-860GM8OAUGD",
        "outputId": "7c9eb823-897a-4d48-81e0-1786d0578a11"
      },
      "source": [
        "print(len(all_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "621300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9ZzV6uS6nJt"
      },
      "source": [
        "all_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_ir7-CzSFlv"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kDDTwD7Tg5N"
      },
      "source": [
        "## Missing Values\n",
        "Let's check how many missing values are in the data set and how can we deal with them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlDC3bdjGHFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d063f7b0-c5ce-478c-e013-17d75c7758c1"
      },
      "source": [
        "all_data_na = (all_data.isnull().sum()).sort_values(ascending = False)\n",
        "all_data_na = all_data_na.drop(all_data_na[all_data_na.values == 0].index)\n",
        "\n",
        "Missing_data = pd.DataFrame({'Missing Numbers' :all_data_na})\n",
        "print(Missing_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Missing Numbers]\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1j-ByWaTpXo"
      },
      "source": [
        "#### SO there are no Missing Values in the input data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIVN9l45N5f1"
      },
      "source": [
        "## Distribution of Numerical Variables\n",
        "We now explore the distribution of numerical variables. We will apply the log1p function to all the skewed numerical variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs0XhG-DN5PQ"
      },
      "source": [
        "# take the numerical features\n",
        "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
        "\n",
        "# compute the skewness but only for non missing variables (we already imputed them but just in case ...)\n",
        "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
        "\n",
        "skewness = pd.DataFrame({\"Variable\":skewed_feats.index, \"Skewness\":skewed_feats.values})\n",
        "# select the variables with a skewness above a certain threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr-JEHjAcURO"
      },
      "source": [
        "skewness = skewness.sort_values('Skewness', ascending=[0])\n",
        "\n",
        "f, ax = plt.subplots(figsize=(8,6))\n",
        "plt.xticks(rotation='90')\n",
        "sns.barplot(x=skewness['Variable'], y=skewness['Skewness'])\n",
        "plt.ylim(0,25)\n",
        "plt.xlabel('Numerical Variables', fontsize=15)\n",
        "plt.ylabel('Skewness', fontsize=15)\n",
        "plt.title('', fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCRCkdSgPFs-"
      },
      "source": [
        "Let's apply the logarithmic transformation to all the variables with a skewness above a certain threshold (0.75). Then, replot the skewness of attributes. Note that to have a fair comparison the two plots should have the same scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAsAIMrMPFP9",
        "outputId": "b0b526af-b724-4765-8d0f-950f6f19148b"
      },
      "source": [
        "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
        "all_data[skewed_feats.index] = np.log1p(all_data[skewed_feats.index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log1p\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in log1p\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDTkPBikPKBt"
      },
      "source": [
        "# compute the skewness but only for non missing variables (we already imputed them but just in case ...)\n",
        "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
        "skewness_new = pd.DataFrame({\"Variable\":skewed_feats.index, \"Skewness\":skewed_feats.values})\n",
        "# select the variables with a skewness above a certain threshold\n",
        "\n",
        "skewness_new = skewness_new.sort_values('Skewness', ascending=[0])\n",
        "\n",
        "f, ax = plt.subplots(figsize=(8,6))\n",
        "plt.xticks(rotation='90')\n",
        "sns.barplot(x=skewness_new['Variable'], y=skewness_new['Skewness'])\n",
        "plt.ylim(0,25)\n",
        "plt.xlabel('Numerical Variables', fontsize=15)\n",
        "plt.ylabel('Skewness', fontsize=15)\n",
        "plt.title('', fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BUNnVmxSN1s"
      },
      "source": [
        "# Utility Functions\n",
        "Next we define some utility functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTNoUrIyQJ1J"
      },
      "source": [
        "def PrintConfusionMatrix(model, true_y, predicted_y, positive=1, negative=-1):\n",
        "    cm = confusion_matrix(true_y,predicted_y)\n",
        "    print(\"\\t\"+str(model.classes_[0])+\"\\t\"+str(model.classes_[1]))\n",
        "    print(str(model.classes_[0]) + \"\\t\",cm[0][0],\"\\t\",cm[0][1])\n",
        "    print(str(model.classes_[1]) + \"\\t\",cm[1][0],\"\\t\",cm[1][1])    \n",
        "\n",
        "def PrintSignificance(stat, c):\n",
        "    if (stat[1]<(1-c)):\n",
        "        print(\"The difference is statistically significant (cf %3.2f p-value=%.4f)\"%(c,stat[1]))\n",
        "    else:\n",
        "        print(\"The difference is not statistically significant (cf %3.2f p-value=%.4f)\"%(c,stat[1]))        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqXeSsm3Ryr2"
      },
      "source": [
        "# Data, Training, and Validation Sets\n",
        "We load the data, define the input data X and the target column y. Next, we set the random seed, define a training/Validation partition, and the crossvalidation procedure we will use to compare the models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MbJcw0-Rn17"
      },
      "source": [
        "target_variable = 'aircon_sum_target_next14d'\n",
        "input_variables = all_data.columns[all_data.columns!=target_variable]\n",
        "\n",
        "X = all_data[input_variables]\n",
        "y = all_data[target_variable]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIhM9_dlVimt"
      },
      "source": [
        "np.random.seed(SEED)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = \\\n",
        "    train_test_split(X, y,\\\n",
        "    test_size= 1/4.0, random_state =SEED, shuffle=True)\n",
        "\n",
        "crossvalidation = StratifiedKFold(n_splits=10, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx6MN5BurSJ8"
      },
      "source": [
        "# Baseline Performance (Majority Voting)\n",
        "At first, let's check what is the class distribution. As we can see the dataset is quite imbalanced with 99.4% of target data that have been classified as a not fault in the following 14 days with only 0.6% of the target data classified as fault. Thus, a very simple model classifying all the test data as not fault would reach an 99.4% accuracy (an impressive result in many applications) however, it would be useless for the real goal of this analysis, that is, to create a model to identify almost all faults."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2tYnIApV3TZ",
        "outputId": "ef06a83e-b4aa-4bcb-e2ab-3261f55893f3"
      },
      "source": [
        "print(\"Class %2d  %.1f%%\\nClass %2d  %.1f%%\\n\"%((y.value_counts()/y.shape[0]).index[0],100*(y.value_counts()/y.shape[0]).values[0],(y.value_counts()/y.shape[0]).index[1],100*(y.value_counts()/y.shape[0]).values[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class  0  99.4%\n",
            "Class  1  0.6%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv86JkQ3xvUd"
      },
      "source": [
        "# Model Evaluation\n",
        "We now evaluate different models using some setup we investigated early. We will consider some basic methods (linear regression, naive bayes, and k-NN) as well as ensemble methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOt_5n0OxRHN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egb9rlr3S4qP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}